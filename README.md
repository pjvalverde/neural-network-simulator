# ğŸ§  SimulaciÃ³n Interactiva de Red Neuronal

Una aplicaciÃ³n web educativa que simula una red neuronal con descenso de gradiente, permitiendo visualizar en tiempo real cÃ³mo aprende la red y cÃ³mo se reduce la funciÃ³n de costo.

## ğŸ¯ CaracterÃ­sticas Principales

### âœ¨ Funcionalidades Educativas

- **VisualizaciÃ³n de la Red Neuronal**: RepresentaciÃ³n grÃ¡fica de la arquitectura con neuronas, conexiones y pesos
- **Descenso de Gradiente en Tiempo Real**: Observa cÃ³mo se actualizan los pesos durante el entrenamiento
- **GrÃ¡fica de FunciÃ³n de Costo**: VisualizaciÃ³n de la convergencia del error a lo largo de las Ã©pocas
- **CÃ¡lculos Paso a Paso**: Desglose matemÃ¡tico detallado de cada operaciÃ³n
- **Controles Interactivos**: Ajusta parÃ¡metros y observa los efectos inmediatamente

### ğŸ”§ Controles Disponibles

- **Tasa de Aprendizaje**: Controla quÃ© tan rÃ¡pido aprende la red (0.01 - 1.0)
- **Salida Objetivo**: Define el valor que la red debe aprender a producir
- **FunciÃ³n de ActivaciÃ³n**: Elige entre Sigmoid, Tanh o ReLU
- **Modos de Entrenamiento**: 
  - Entrenamiento continuo
  - Paso a paso para anÃ¡lisis detallado
  - Pausa y reinicio

### ğŸ“Š Visualizaciones

1. **Red Neuronal Interactiva**:
   - Neuronas con colores que representan activaciones
   - Conexiones con grosor proporcional al peso
   - Colores verde/rojo para pesos positivos/negativos
   - Etiquetas dinÃ¡micas de pesos y bias

2. **GrÃ¡fica de Convergencia**:
   - EvoluciÃ³n del error en tiempo real
   - Ejes escalados automÃ¡ticamente
   - Puntos de datos para anÃ¡lisis detallado

3. **Panel de CÃ¡lculos**:
   - Forward pass paso a paso
   - Backward pass con gradientes
   - ActualizaciÃ³n de pesos explicada

## ğŸ—ï¸ Arquitectura de la Red

La simulaciÃ³n implementa una red neuronal feedforward con:

- **Capa de Entrada**: 2 neuronas (valores fijos: [1, 0])
- **Capa Oculta**: 2 neuronas con bias
- **Capa de Salida**: 1 neurona con bias

### Pesos Iniciales (segÃºn imagen de referencia):
```
w1 = 1.0    (entrada 1 â†’ neurona oculta 1)
w2 = 0.5    (entrada 0 â†’ neurona oculta 1)
w3 = 1.0    (entrada 1 â†’ neurona oculta 2)
w4 = -0.5   (entrada 0 â†’ neurona oculta 2)
w5 = 1.0    (neurona oculta 1 â†’ salida)
w6 = 1.0    (neurona oculta 2 â†’ salida)

b1 = 0.5    (bias neurona oculta 1)
b2 = 0.0    (bias neurona oculta 2)
b3 = 0.5    (bias neurona de salida)
```

## ğŸ§® Algoritmo Implementado

### Forward Pass
1. **Capa Oculta**:
   ```
   z1 = (input1 Ã— w1) + (input2 Ã— w2) + b1
   a1 = Ïƒ(z1)
   
   z2 = (input1 Ã— w3) + (input2 Ã— w4) + b2
   a2 = Ïƒ(z2)
   ```

2. **Capa de Salida**:
   ```
   z3 = (a1 Ã— w5) + (a2 Ã— w6) + b3
   output = Ïƒ(z3)
   ```

3. **FunciÃ³n de Costo**:
   ```
   Error = 0.5 Ã— (target - output)Â²
   ```

### Backward Pass (RetropropagaciÃ³n)
1. **Gradientes de Salida**:
   ```
   Î´3 = (output - target) Ã— Ïƒ'(output)
   dW5 = Î´3 Ã— a1
   dW6 = Î´3 Ã— a2
   dB3 = Î´3
   ```

2. **Gradientes de Capa Oculta**:
   ```
   Î´1 = Î´3 Ã— w5 Ã— Ïƒ'(a1)
   Î´2 = Î´3 Ã— w6 Ã— Ïƒ'(a2)
   
   dW1 = Î´1 Ã— input1
   dW2 = Î´1 Ã— input2
   dW3 = Î´2 Ã— input1
   dW4 = Î´2 Ã— input2
   dB1 = Î´1
   dB2 = Î´2
   ```

3. **ActualizaciÃ³n de Pesos**:
   ```
   w_new = w_old - Î± Ã— dW
   b_new = b_old - Î± Ã— dB
   ```

## ğŸš€ Uso de la AplicaciÃ³n

### Inicio RÃ¡pido
1. Abre `index_simple.html` en tu navegador
2. Observa la red neuronal y sus valores iniciales
3. Ajusta los parÃ¡metros segÃºn tus necesidades
4. Haz clic en "Iniciar Entrenamiento" para ver el aprendizaje automÃ¡tico
5. Usa "Paso a Paso" para anÃ¡lisis detallado

### Controles de Teclado
- **Espacio**: Iniciar/Pausar entrenamiento
- **R**: Reiniciar red neuronal
- **S**: Ejecutar un paso de entrenamiento

### Experimentos Sugeridos

1. **Efecto de la Tasa de Aprendizaje**:
   - Prueba con Î± = 0.01 (lento pero estable)
   - Prueba con Î± = 0.5 (rÃ¡pido pero puede oscilar)
   - Prueba con Î± = 1.0 (muy rÃ¡pido, puede diverger)

2. **Diferentes Funciones de ActivaciÃ³n**:
   - Sigmoid: Suave, valores entre 0 y 1
   - Tanh: Suave, valores entre -1 y 1
   - ReLU: Lineal para valores positivos

3. **Objetivos de Aprendizaje**:
   - Target = 0.5: FÃ¡cil de alcanzar
   - Target = 0.1: Requiere mÃ¡s entrenamiento
   - Target = 0.9: Observa la saturaciÃ³n

## ğŸ“ Estructura de Archivos

```
neural-network-simulator/
â”œâ”€â”€ index_simple.html          # AplicaciÃ³n principal
â”œâ”€â”€ neuralNetwork.js           # LÃ³gica de la red neuronal
â”œâ”€â”€ simpleVisualization.js     # Visualizaciones con Canvas
â”œâ”€â”€ simpleApp.js              # Controlador principal
â”œâ”€â”€ README.md                 # Esta documentaciÃ³n
â””â”€â”€ neural_network_analysis.md # AnÃ¡lisis tÃ©cnico
```

## ğŸ“ Valor Educativo

Esta simulaciÃ³n es ideal para:

- **Estudiantes de Machine Learning**: Comprender conceptos fundamentales
- **Profesores**: Demostrar algoritmos de manera visual
- **Desarrolladores**: Ver implementaciÃ³n prÃ¡ctica de redes neuronales
- **Investigadores**: Experimentar con parÃ¡metros y observar efectos

### Conceptos Demostrados

1. **Forward Propagation**: CÃ³mo fluyen los datos a travÃ©s de la red
2. **Backward Propagation**: CÃ³mo se calculan y propagan los gradientes
3. **Gradient Descent**: CÃ³mo se optimizan los pesos
4. **FunciÃ³n de Costo**: CÃ³mo se mide y reduce el error
5. **Convergencia**: CÃ³mo la red aprende a aproximar la funciÃ³n objetivo

## ğŸ”¬ Aspectos TÃ©cnicos

### TecnologÃ­as Utilizadas
- **HTML5 Canvas**: Para visualizaciones de alta performance
- **JavaScript ES6+**: LÃ³gica moderna y eficiente
- **CSS3**: DiseÃ±o responsivo y atractivo
- **Sin dependencias externas**: Funciona offline

### Optimizaciones Implementadas
- Renderizado eficiente con Canvas nativo
- LimitaciÃ³n de puntos en grÃ¡ficas para performance
- ActualizaciÃ³n selectiva de elementos visuales
- GestiÃ³n de memoria para historial de costos

## ğŸ¯ Casos de Uso

### En el Aula
- IntroducciÃ³n a redes neuronales
- DemostraciÃ³n de gradient descent
- AnÃ¡lisis de hiperparÃ¡metros
- ComparaciÃ³n de funciones de activaciÃ³n

### Autoaprendizaje
- ExperimentaciÃ³n interactiva
- ComprensiÃ³n visual de conceptos
- AnÃ¡lisis paso a paso de algoritmos
- ValidaciÃ³n de conocimientos teÃ³ricos

### InvestigaciÃ³n
- Prototipado rÃ¡pido de ideas
- VisualizaciÃ³n de comportamientos
- Testing de parÃ¡metros
- ComunicaciÃ³n de resultados

## ğŸš€ PrÃ³ximas Mejoras

- Soporte para mÃºltiples capas ocultas
- Diferentes algoritmos de optimizaciÃ³n (Adam, RMSprop)
- Datasets personalizables
- ExportaciÃ³n de resultados
- Modo de comparaciÃ³n de algoritmos

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para uso educativo y de investigaciÃ³n.

---

**Â¡Explora, experimenta y aprende sobre redes neuronales de manera interactiva!** ğŸ§ âœ¨

